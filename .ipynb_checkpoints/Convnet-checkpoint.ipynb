{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Try1 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# matplotlib inline command allows us to see right below the code.\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import input_data\n",
    "import warnings # Ignore dumb warnings about deprecation I'll worry about this when I'm dead\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Stuff for the plt figures\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trX.shape (55000, 784)\n",
      "trY.shape (55000, 10)\n",
      "teX.shape (10000, 784)\n",
      "teY.shape (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"trX.shape\", trX.shape)\n",
    "print(\"trY.shape\", trY.shape)\n",
    "print(\"teX.shape\", teX.shape)\n",
    "print(\"teY.shape\", teY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (44000, 784)\n",
      "X_val.shape (11000, 784)\n",
      "y_train.shape (44000, 10)\n",
      "y_val.shape (11000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Turn some into validation: We want 1/5th\n",
    "FRACTION_VAL = 5\n",
    "\n",
    "N,D = trX.shape\n",
    "seq = np.array(range(N))\n",
    "np.random.shuffle(seq)\n",
    "\n",
    "X_train = trX[seq[N/FRACTION_VAL:]]\n",
    "y_train = trY[seq[N/FRACTION_VAL:]]\n",
    "X_val = trX[seq[:N/FRACTION_VAL]]\n",
    "y_val = trY[seq[:N/FRACTION_VAL]]\n",
    "\n",
    "print(\"X_train.shape\" , X_train.shape)\n",
    "print(\"X_val.shape\" , X_val.shape)\n",
    "print(\"y_train.shape\" , y_train.shape)\n",
    "print(\"y_val.shape\" , y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels, in order:  [8 4 2 1 3 5 2 4 0 4]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAFzCAYAAAAjYj0YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d492400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's try to visualize some of these. The format of the images are 28x28.\n",
    "SHOW_IMAGE = 10\n",
    "\n",
    "for i in range(SHOW_IMAGE):\n",
    "    plt.subplot(SHOW_IMAGE/5, SHOW_IMAGE/2, i+1)\n",
    "    implot = plt.imshow(X_train[i].reshape((28,28)))\n",
    "    plt.axis('off')\n",
    "\n",
    "print(\"Labels, in order: \", np.where(y_train[:i+1] == 1)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's build a neural network for this!\n",
    "# We have the architecture CONV -> RELU -> FC -> RELU -> FC -> SOFTMAX\n",
    "\n",
    "def init_weight(shape, std = 0.01):\n",
    "    return tf.Variable(tf.random_normal(shape, std))\n",
    "\n",
    "def init_model(params):\n",
    "    X, W0, W1, W2, W3, W4, W5, conv_dropout, fc_dropout = params\n",
    "    \n",
    "    ##### STARTING CONV #####\n",
    "    # First we want to CONV the X to conv_1\n",
    "    conv_0 = tf.nn.conv2d(X, W0, [1,1,1,1], padding='SAME')\n",
    "    batch_0 = tf.nn.batch_normalization(drop_0, mean[0], variance[0], offset[0], scale, variance_epsilon, name=None)\n",
    "    relu_0 = tf.nn.relu(conv_0)\n",
    "    drop_0 = tf.nn.dropout(relu_0, conv_dropout)\n",
    "    # Then, we want to CONV the conv_1 to conv_2\n",
    "    conv_1 = tf.nn.conv2d(drop_0, W1, [1,1,1,1], padding='SAME')\n",
    "    relu_1 = tf.nn.relu(conv_1)\n",
    "    drop_1 = tf.nn.dropout(relu_1, conv_dropout)\n",
    "    \n",
    "    # Then, we want to POOL the conv_2\n",
    "    pool_1 = tf.nn.max_pool(relu_1, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # Then, we want to CONV the pool_2 to conv_3\n",
    "    conv_2 = tf.nn.conv2d(pool_1, W2, [1,1,1,1], padding='SAME')\n",
    "    relu_2 = tf.nn.relu(conv_2)\n",
    "    drop_2 = tf.nn.dropout(relu_2, conv_dropout)\n",
    "\n",
    "    \n",
    "    # Then, we want to POOL the conv_3\n",
    "    pool_2 = tf.nn.max_pool(relu_2, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # Then, we want to CONV the pool_3\n",
    "    conv_3 = tf.nn.conv2d(pool_2, W3, [1,1,1,1], padding='SAME')\n",
    "    relu_3 = tf.nn.relu(conv_3)\n",
    "    drop_3 = tf.nn.dropout(relu_3, conv_dropout)\n",
    "\n",
    "    \n",
    "    ##### STARTING FC #####\n",
    "    # Then we need to unroll this result and start FC\n",
    "    fc_3 = tf.reshape(conv_3, [-1, 7*7*64])\n",
    "    fc_4 = tf.matmul(fc_3, W4)\n",
    "    relu_4 = tf.nn.relu(fc_4)\n",
    "    drop_4 = tf.nn.dropout(relu_4, fc_dropout)\n",
    "    \n",
    "    # Then we need to fc again to get the result\n",
    "    fc_5 = tf.matmul(relu_4, W5)\n",
    "    \n",
    "    answer = fc_5\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Variable is a starting point. tf.random_normal initializes it for us with a stddev\n",
    "input_shape = X_train.shape\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "############################# CONVOLUTIONAL LAYER INITIALIZATION #############################\n",
    "# Each layer is in the form of [NxHxWxC]\n",
    "# We start off with a layer of [Nx28x28x1]\n",
    "# We change it to a layer of [Nx28x28x64] from CONV a filter of [3x3], padding 1\n",
    "# Therefore, we need the weight [filter_height = 3, filter_width = 3, in_channels = 1, out_channels = 64]\n",
    "W0 = init_weight([3,3,1,64])\n",
    "\n",
    "# Then, we change it to a layer of [Nx28x28x64] from CONV a filter of [3x3], padding 1\n",
    "# Therefore, we need the weight [filter_height = 3, filter_width = 3, in_channels = 64, out_channels = 64\n",
    "W1 = init_weight([3,3,64,64])\n",
    "\n",
    "# Then, we change it to a layer of [Nx14x14x64] from POOLING with filter of [2x2] with stride 2\n",
    "# No weights necessary.\n",
    "\n",
    "# Then, we change it to a layer of [Nx14x14x64] from CONV with a filter of [3x3], padding 1\n",
    "# Therefore, we need the weight [filter_height = 3, filter_width = 3, in_channels = 64, out_channels = 128]\n",
    "W2 = init_weight([3,3,64,128])\n",
    "\n",
    "# Then, we get the layer of [Nx7x7x128] from POOLING with filter of [2x2] with stride 2\n",
    "# No weights necessary.\n",
    "\n",
    "# Then, we get the layer of [Nx7x7x64] from CONV with a filter of [3x3], padding 1\n",
    "# Therefore, we need the weight [filter_height = 3, filter_width = 3, in_channels = 128, out_channels = 64]\n",
    "W3 = init_weight([3,3,128,64])\n",
    "################################################################################################\n",
    "\n",
    "############################# FULLY CONNECTED LAYERS INITIALIZATION #############################\n",
    "# We need to unroll the parameters of the CONV layer, and we get an input of [Nx(7x7x64)]\n",
    "W4 = init_weight([7*7*64, 300])\n",
    "\n",
    "# Then, we do one more FC before we feed into softmax:\n",
    "W5 = init_weight([300, 10])\n",
    "################################################################################################\n",
    "\n",
    "#################################### EXTRA PARAMETERS ####################################\n",
    "conv_dropout = tf.placeholder(tf.float32)\n",
    "fc_dropout = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparams:\n",
    "learning_rate = 1e-4\n",
    "reg_rate = 1e-4\n",
    "\n",
    "hypothesis = init_model((X, W0, W1, W2, W3, W4, W5, conv_dropout, fc_dropout))\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(hypothesis, y))\n",
    "\n",
    "# Regularization \n",
    "cross_entropy += reg_rate * (tf.nn.l2_loss(W0)+tf.nn.l2_loss(W1)+tf.nn.l2_loss(W2)\n",
    "                             +tf.nn.l2_loss(W3)+tf.nn.l2_loss(W4)+tf.nn.l2_loss(W5))\n",
    "\n",
    "# Using Adam to optimize\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "predict_op = tf.argmax(hypothesis, 1)\n",
    "\n",
    "# Let's log it to see our progress!\n",
    "loss_summary = tf.scalar_summary('loss', cross_entropy)\n",
    "\n",
    "# Reshape the matrices into the correct conv dimensions:\n",
    "X_train = X_train.reshape(-1,28,28,1)\n",
    "X_val = X_val.reshape(-1,28,28,1)\n",
    "teX = teX.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :  1.24869e+07\n",
      "0 0.09765625\n",
      "Loss :  1.07745e+07\n",
      "1 0.13671875\n",
      "Loss :  8.54806e+06\n",
      "2 0.11328125\n",
      "Loss :  6.9705e+06\n",
      "3 0.14453125\n",
      "Loss :  5.64172e+06\n",
      "4 0.12890625\n",
      "Loss :  5.25852e+06\n",
      "5 0.1875\n",
      "Loss :  4.63622e+06\n",
      "6 0.203125\n",
      "Loss :  4.17056e+06\n",
      "7 0.1796875\n",
      "Loss :  3.45193e+06\n",
      "8 0.26171875\n",
      "Loss :  3.39095e+06\n",
      "9 0.2734375\n",
      "Loss :  2.8567e+06\n",
      "10 0.2734375\n",
      "Loss :  2.87599e+06\n",
      "11 0.3828125\n",
      "Loss :  2.91606e+06\n",
      "12 0.3984375\n",
      "Loss :  2.32616e+06\n",
      "13 0.39453125\n",
      "Loss :  2.19092e+06\n",
      "14 0.43359375\n",
      "Loss :  2.223e+06\n",
      "15 0.4453125\n",
      "Loss :  1.94056e+06\n",
      "16 0.47265625\n",
      "Loss :  2.4266e+06\n",
      "17 0.5078125\n",
      "Loss :  2.23955e+06\n",
      "18 0.4609375\n",
      "Loss :  1.79095e+06\n",
      "19 0.546875\n",
      "Loss :  1.33303e+06\n",
      "20 0.55859375\n",
      "Loss :  1.40051e+06\n",
      "21 0.4765625\n",
      "Loss :  1.29897e+06\n",
      "22 0.62890625\n",
      "Loss :  1.40351e+06\n",
      "23 0.5390625\n",
      "Loss :  1.82460e+06\n",
      "24 0.5625\n",
      "Loss :  1.47272e+06\n",
      "25 0.58203125\n",
      "Loss :  1.58832e+06\n",
      "26 0.6171875\n",
      "Loss :  1.05445e+06\n",
      "27 0.65234375\n",
      "Loss :  1.6348e+06\n",
      "28 0.68359375\n",
      "Loss :  1.662e+06\n",
      "29 0.6328125\n",
      "Loss :  1.40786e+06\n",
      "30 0.5625\n",
      "Loss :  878385.0\n",
      "31 0.625\n",
      "Loss :  1.49385e+06\n",
      "32 0.6640625\n",
      "Loss :  711702.0\n",
      "33 0.65234375\n",
      "Loss :  1.22882e+06\n",
      "34 0.68359375\n",
      "Loss :  833605.0\n",
      "35 0.66015625\n",
      "Loss :  971511.0\n",
      "36 0.67578125\n",
      "Loss :  999288.0\n",
      "37 0.74609375\n",
      "Loss :  1.13713e+06\n",
      "38 0.74609375\n",
      "Loss :  1.29319e+06\n",
      "39 0.66015625\n",
      "Loss :  1.02703e+06\n",
      "40 0.6796875\n",
      "Loss :  1.01399e+06\n",
      "41 0.67578125\n",
      "Loss :  1.31792e+06\n",
      "42 0.75390625\n",
      "Loss :  1.06089e+06\n",
      "43 0.7265625\n",
      "Loss :  850281.0\n",
      "44 0.70703125\n",
      "Loss :  888257.0\n",
      "45 0.6796875\n",
      "Loss :  945017.0\n",
      "46 0.6953125\n",
      "Loss :  864842.0\n",
      "47 0.7734375\n",
      "Loss :  911149.0\n",
      "48 0.75390625\n",
      "Loss :  905144.0\n",
      "49 0.75\n",
      "Loss :  752431.0\n",
      "50 0.7578125\n",
      "Loss :  829439.0\n",
      "51 0.7578125\n",
      "Loss :  794417.0\n",
      "52 0.7578125\n",
      "Loss :  826612.0\n",
      "53 0.7734375\n",
      "Loss :  1.02995e+06\n",
      "54 0.76171875\n",
      "Loss :  748245.0\n",
      "55 0.76171875\n",
      "Loss :  875897.0\n",
      "56 0.7890625\n",
      "Loss :  878267.0\n",
      "57 0.765625\n",
      "Loss :  657656.0\n",
      "58 0.7421875\n",
      "Loss :  698120.0\n",
      "59 0.7734375\n",
      "Loss :  587761.0\n",
      "60 0.75390625\n",
      "Loss :  899124.0\n",
      "61 0.71875\n",
      "Loss :  579549.0\n",
      "62 0.83984375\n",
      "Loss :  629385.0\n",
      "63 0.76953125\n",
      "Loss :  624296.0\n",
      "64 0.7890625\n",
      "Loss :  805277.0\n",
      "65 0.78515625\n",
      "Loss :  734185.0\n",
      "66 0.80859375\n",
      "Loss :  730995.0\n",
      "67 0.796875\n",
      "Loss :  635407.0\n",
      "68 0.7578125\n",
      "Loss :  545766.0\n",
      "69 0.83984375\n",
      "Loss :  600210.0\n",
      "70 0.8046875\n",
      "Loss :  699146.0\n",
      "71 0.8046875\n",
      "Loss :  885888.0\n",
      "72 0.8203125\n",
      "Loss :  500900.0\n",
      "73 0.796875\n",
      "Loss :  640524.0\n",
      "74 0.8046875\n",
      "Loss :  592356.0\n",
      "75 0.828125\n",
      "Loss :  443894.0\n",
      "76 0.8046875\n",
      "Loss :  449812.0\n",
      "77 0.79296875\n",
      "Loss :  583840.0\n",
      "78 0.828125\n",
      "Loss :  540585.0\n",
      "79 0.81640625\n",
      "Loss :  708843.0\n",
      "80 0.78125\n",
      "Loss :  563251.0\n",
      "81 0.85546875\n",
      "Loss :  634315.0\n",
      "82 0.8046875\n",
      "Loss :  564644.0\n",
      "83 0.82421875\n",
      "Loss :  450027.0\n",
      "84 0.80859375\n",
      "Loss :  452670.0\n",
      "85 0.8203125\n",
      "Loss :  594549.0\n",
      "86 0.8515625\n",
      "Loss :  446056.0\n",
      "87 0.83984375\n",
      "Loss :  594830.0\n",
      "88 0.8125\n",
      "Loss :  515477.0\n",
      "89 0.83203125\n",
      "Loss :  329427.0\n",
      "90 0.7890625\n",
      "Loss :  547492.0\n",
      "91 0.83984375\n",
      "Loss :  759949.0\n",
      "92 0.8515625\n",
      "Loss :  650587.0\n",
      "93 0.828125\n",
      "Loss :  470526.0\n",
      "94 0.8359375\n",
      "Loss :  791207.0\n",
      "95 0.86328125\n",
      "Loss :  558851.0\n",
      "96 0.82421875\n",
      "Loss :  615891.0\n",
      "97 0.828125\n",
      "Loss :  350250.0\n",
      "98 0.859375\n",
      "Loss :  584058.0\n",
      "99 0.8515625\n",
      "Model saved in file: model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    #merged = tf.merge_all_summaries([loss_summary])\n",
    "    writer = tf.train.SummaryWriter('logs', sess.graph_def)\n",
    "    # you need to initialize all variables\n",
    "    tf.initialize_all_variables().run()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    for i in range(100):\n",
    "        NUM_BATCHES = 10\n",
    "        for j in range(NUM_BATCHES):\n",
    "            batch_mask = np.random.choice(44000, 128)\n",
    "            summary_str, _, cur_loss = sess.run([loss_summary, train_op, cross_entropy], \n",
    "                                                feed_dict={X: X_train[batch_mask], \n",
    "                                                           y: y_train[batch_mask],\n",
    "                                                           conv_dropout: 0.8, \n",
    "                                                           fc_dropout: 0.5})\n",
    "\n",
    "        test_indices = np.arange(len(X_val)) # Get a validation batch\n",
    "        np.random.shuffle(test_indices)\n",
    "        test_indices = test_indices[0:256]\n",
    "\n",
    "        writer.add_summary(summary_str, i)\n",
    "        print(\"Loss : \" , cur_loss)\n",
    "        print(i, np.mean(np.argmax(y_val[test_indices], axis=1) ==\n",
    "                         sess.run(predict_op, feed_dict={X: X_val[test_indices],\n",
    "                                                         y: y_val[test_indices],\n",
    "                                                         conv_dropout: 1.0,\n",
    "                                                         fc_dropout: 1.0})))\n",
    "        \n",
    "    save_path = saver.save(sess, \"model.ckpt\") # checkpoint file\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers :  [7 2 1 0 4 1 7 9 5 9]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAFzCAYAAAAjYj0YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b10e2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"model.ckpt\")\n",
    "    answers = sess.run(predict_op, feed_dict={X: teX[:SHOW_IMAGE],\n",
    "                                     y: teY[:SHOW_IMAGE],\n",
    "                                     conv_dropout: 1.0,\n",
    "                                     fc_dropout: 1.0})\n",
    "    for i in range(SHOW_IMAGE):\n",
    "        plt.subplot(SHOW_IMAGE/5, SHOW_IMAGE/2, i+1)\n",
    "        implot = plt.imshow(teX[i].reshape((28,28)))\n",
    "        plt.axis('off')\n",
    "    print(\"Answers : \", answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
