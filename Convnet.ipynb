{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Convnet #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# matplotlib inline command allows us to see right below the code.\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import input_data\n",
    "import warnings # Ignore dumb warnings about deprecation I'll worry about this when I'm dead\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Stuff for the plt figures\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trX.shape (55000, 784)\n",
      "trY.shape (55000, 10)\n",
      "teX.shape (10000, 784)\n",
      "teY.shape (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"trX.shape\", trX.shape)\n",
    "print(\"trY.shape\", trY.shape)\n",
    "print(\"teX.shape\", teX.shape)\n",
    "print(\"teY.shape\", teY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (44000, 784)\n",
      "X_val.shape (11000, 784)\n",
      "y_train.shape (44000, 10)\n",
      "y_val.shape (11000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Turn some into validation: We want 1/5th\n",
    "FRACTION_VAL = 5\n",
    "\n",
    "N,D = trX.shape\n",
    "seq = np.array(range(N))\n",
    "np.random.shuffle(seq)\n",
    "\n",
    "X_train = trX[seq[N/FRACTION_VAL:]]\n",
    "y_train = trY[seq[N/FRACTION_VAL:]]\n",
    "X_val = trX[seq[:N/FRACTION_VAL]]\n",
    "y_val = trY[seq[:N/FRACTION_VAL]]\n",
    "\n",
    "print(\"X_train.shape\" , X_train.shape)\n",
    "print(\"X_val.shape\" , X_val.shape)\n",
    "print(\"y_train.shape\" , y_train.shape)\n",
    "print(\"y_val.shape\" , y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels, in order:  [8 4 2 1 3 5 2 4 0 4]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAFzCAYAAAAjYj0YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xe0XUX5MOC59EQQAqgEFhAggkuaSAcBUYIsgYg0aYIi\nGJoIoqEIAZFIpAgoiCG0JKJSpKOINEMPRLooNQgmGEqEFXrgfn/8Picz25yTyTnn3tx77vP89c56\nz917yNzysmf2TEdnZ2cAAKC++eZ1BwAAegNFEwBAAUUTAEABRRMAQAFFEwBAAUUTAEABRRMAQAFF\nEwBAAUUTAECBBbr6Bh0dHbYcn8c6Ozs7WnEdY9kzGM/2YSzbi/FsH7XG0pMmAIACiiYAgAKKJgCA\nAoomAIACiiYAgAKKJgCAAoomAIACiiYAgAKKJgCAAoomAIACiiYAgAKKJgCAAl1+YC/0JAMHDpxt\nHEIIf/3rX1t+v4022ijG99xzT5Y7/vjjY3ziiSe2/N4AtJYnTQAABRRNAAAFTM/Rp4wePTrGQ4YM\nyXIrr7xyjKdOndqS+62zzjox7uzszHIrrbRSS+7BnKVTsdtuu22W+8UvfhHjRRZZJMtdeeWVMf72\nt7+d5V599dVWdrHPGTZsWNb+1a9+FePqdHU6lU3PtMYaa8T4O9/5TpbbeeedYzxgwIAs19HRUfOa\n6e/MSZMmZbnDDz88xnfeeefcdbYJnjQBABRQNAEAFFA0AQAU6FNrmtZbb70YL7744g1d46mnnorx\nP//5zyz3rW99K8abb755lttnn30auh/NWXbZZbP2ZpttFuOHHnooy7322mtN32+VVVbJ2sccc0yM\nZ8yYkeUuuOCCpu/H7O2www5Z+5JLLolxv379an5ddd3ZV7/61RifddZZWW7ChAnNdLHPe+mll7J2\n+m+/2mqrdXd3KLDLLrtk7Z122inG6VrB6dOnZ59Lf7emawjnJP19uueee2a5q6++OsZLL7108TWb\n5UkTAEABRRMAQIG2m55Lp+COOuqoLPelL30pxv3792/o+k8//XSMTzjhhCyXPnZ8/fXXG7o+zUtf\nab300kuzXDote+yxx2a5d999t+l7H3bYYVl7ueWWi/ELL7yQ5brzNdl2VJ0KTV9zrm4PkG4lcOON\nN2a5Qw45JMbLL798lrvtttua7iez95e//GVed4EC6bKTkSNHZrmbbropxunP369//evsczNnzmzo\n3gcffHCMq9Nz06ZNa+iazfKkCQCggKIJAKCAogkAoECvXNO0xBJLxPj000/PcnvttVeMF1gg/89L\nX4OsrlU46aSTYrzgggvG+Bvf+Eb2uS9/+cuzjUMIYeGFF47x3XffXbP/dK1DDz00xptuummWS199\nveWWW1pyvwMPPDDG+++/f83PpcdE0Jh0645TTjkly33sYx+L8QcffJDl0iM7qls9fPjhhzHeYost\nWtJP5uw///nPvO4CBaZMmRLjFVdcMcu1Yh3ooEGDYvyzn/0syw0dOjTGN998c5bbe++9m753Izxp\nAgAooGgCACjQK6bn0sd3IYQwbty4GFenX9JXG6+55posl06dlJ5Qftddd2XtM888M8bVk5xTP/7x\nj4uuT/O23377rH3cccfFuDpNs++++zZ9v+q07/rrrx/jhRZaKMtNnDgxxtVHz5TZYIMNYpxOcabT\n4SHk02zVqbsxY8bUvP4yyywT45/+9KdZLt3F/V//+ldhjynxla98ZV53gQJ//OMfW3q9tdZaK2un\nW/V87nOfy3Lp8pv0dIUQGt/GoFmeNAEAFFA0AQAUUDQBABToFWua7rnnnqz98Y9/PMbPPvtsljvt\ntNNiPHr06KbvXT1t+2tf+1rNz5566qkxfvTRR5u+N7WtscYaMa6uV5lvvln/LzB27Ngsd+211zZ9\n7+patuq2FKn0qJ1WvJ7bruaff/4Y77bbblnu5JNPjnF1HVNq0qRJMf7hD39YfO8TTzwxxtXT0i+6\n6KIYP/PMM8XXZM6qW7Z0dHTMNqb3O/zww2M8fPjwLDd16tQYV48m64lrgz1pAgAooGgCACjQK6bn\nPvGJT2Ttzs7OGFdf427FlFz6SvmVV15Zsy+33nprljv22GNjXH3VneZ85CMfydrplE06XRtCCPfd\nd1+Mzz333Jbcf8CAATGuTh+lqrt+/+lPf2rJ/dvdjjvuGOPx48cXfU313zadmq9n7bXXztpf//rX\na342fR2a1tpkk02ydvp7/b333uvu7tCA9PSMdAuJI488MvvcOuusE+Pbb789y33/+9+P8UMPPdTi\nHraeJ00AAAUUTQAABRRNAAAFesWapnrSE+1DCOGdd96J8f333198nfTr0lfKP/WpT2Wfe+WVV2Jc\nPZJjXm3r3q769esX4x/96EdZbtttt43x448/nuW22267GJcelzMn6XYS6bEpIeTfE2eddVaWS9dp\nMMsWW2yRtavHnqSmT58e43QcqkeelP5b33nnnVk73cZg5MiRWe7hhx8uuiatVV33Qs9QbwuedLuA\nN998M/vceeedF+Ojjjoqy73xxhst7GHX86QJAKCAogkAoECvmJ7baaedsvY555wT41VXXTXLnX/+\n+Q3dI32c+P7779f83KKLLhrj6tRgOk1U7Vc6TfTkk09mubT997//vbDH7W/UqFExru7Cne6uXX3N\nvxVTcum2EyGEsOaaa9b87Lhx42L8j3/8o+l79wWDBw/O2iuuuGKM0+m4EPKp2Hvvvbfo+umu8CGE\ncOaZZ8a4f//+WW7y5Mkxrm5bYHqVvmaRRRbJ2gcffHCM09/JIeRLUtLteY455pjsc9W/eb2ZJ00A\nAAUUTQAABRRNAAAFesWapquuuipr33333TFOX0sPIYSDDjooxukW71Xrrbde1q5u6f9fF198cdZO\nT99OT25uxuuvvx7jyy+/PMuddNJJMX7hhRdacr+eqnrCdbqOacaMGVlu5513jvFNN93U8r6kp9uH\nkG8zUB2Hn/zkJy2/f7t77bXXsvYNN9wQ4/333z/LvfTSS0XXTNehVbcwOOSQQ2Jc/V468MADY5z+\nLDLv3HXXXfO6C31KekzVJZdckuWGDh0a41tuuSXLpb/7brvtti7qXc/iSRMAQAFFEwBAgY6ufqW2\no6OjR76zW91N+LDDDpttfO6557bkfgMHDozxrrvumuU22GCDGO++++5Z7rnnnovxF7/4xSyXvipd\nT2dnZ8ecPzVnrRjLZZZZJmvX+ncPIYSFFlooxtWdtuuNy0YbbRTjT37yk8V922WXXWI8aNCgmn2p\nnsA+bdq0GF9//fVZLp0ubpWeNJ49ybBhw2Jc7/sj/VwIIVx44YUx/uCDD1rfsTr62lguscQSMX7q\nqaey3NJLLx3jHXbYIctdc801XduxFumt45luJTB8+PAsl/4Nqi6hSMelt+3sPSe1xtKTJgCAAoom\nAIACfWp6Lp0a+tvf/pbl0jei1l577W7rUwj5Wz977bVXlkt3KK4eYpm+QVZPT3pknE5lhZA/km8H\n1bcf0wMtW6UnjWd3SHfX33rrrWOcvvETQr4L8WKLLVZ8/dGjR8f41ltvzXLV8Wy1vjaWqUcffTRr\nr7766jGunqjw9NNPd0ufmtVbxzN9u7T6NnB6CkZVejLDH/7whxhPnDgx+1x6akNveUPV9BwAQBMU\nTQAABRRNAAAF+tSapuuuuy7GX/7yl7PcY489FuPuXtNUz8033xzjLbfcMsvNP//8RdfoSfPsH374\nYSu6Uqy6S+2aa64Z43rrqaqvnh999NExfv7552t+XXW38Hvvvbeon3OjJ41nq8w336z/f0u3fggh\nhHHjxsW43i7/qfT09RBCuOOOO2JcHaP0xIH090AIITzzzDNF92tUO45lqXprmlZYYYUs9+KLL3ZL\nn5rVDuOZbgsRQgjbbLNNjNdaa60st91228V4xRVXjHF1TeHLL78c45122inL3XnnnY13tgtZ0wQA\n0ARFEwBAgbaenttiiy2ydjrVVX21ON2B9u233+7ajlWkhwCnh9SGEMLpp58e4/S1zdl9tpae9Mi4\nVYccp1Ot1cNfU2+99VbWvuCCC2Jc3X09fX12q622ynI96QDRnjSejVpllVWy9vjx42Oc7uhez5tv\nvpm1zz777BhXd5AvPfS3u7XDWM6NDTfcMMbVaZl0R+nBgwdnuenTp3dtx1qkr41nKh2z4447Lsvt\nueeeMa7uHH7EEUfEeOzYsVmuu5dzpEzPAQA0QdEEAFBA0QQAUGCBOX+kd0lfSU6PVQghf605XRMT\nQvevY0ptuummMT7jjDNqfq63vHZbT73/vq5QXRtRXceUuvrqq2Pck9YwtYshQ4bE+Pzzz89yyy+/\nfNE1ZsyYEeN0LUQIIYwZM6aJ3tEd0iM00t/HIYQwZcqUGPeWNUzMkh51s88++2S59Dii6s9pus60\nOu7p7+SewpMmAIACiiYAgAJtNz235JJLxrj62njqsssu647uROnu0+mJ0iHku01XpY8uzzzzzNZ3\nrA0ttdRSMb7kkktqfm7atGlZuzouNOdTn/pU1j7vvPNiXDodF0IIzz33XIzTx/49dSdhaku3iUi3\nWqG9XX/99TGubiswfPjwGH/xi1/McqbnAAB6KUUTAEABRRMAQIG2W9NU6qCDDsrap512WtHXffSj\nH41x9bXKetfv379/jKunSKdHfRx11FFZ7pxzzonxe++9V9THvi49Emf99dev+blRo0Zl7VdffbXL\n+tRXpOuYzj333CyXnoJez6RJk7L2LrvsEuPJkyc33jnmuU984hMxrh7hNXPmzO7uDv/fpz/96Rg/\n8cQTWa4VR62l69dWXXXVmp976qmnmr5XV/OkCQCggKIJAKBARysevdW9QTef1tyvX78Yjxs3Lstt\ns802Ma6ekL7AArNmKgcMGFDz+ukutvVOYP7ggw+ydvrI8x//+EeWO+WUU2L8wAMP1Lxmo9r95O30\n0XIIITz44IMxTneIDyEf98UWW6xrO9ZFetJ4Lrzwwln7qquuinH681ZV/fk7++yzY3zqqadmudde\ne62ZLvZoPWksu8Po0aNjvN9++2W5dEuV6m7vvUVvHc+bb745xr/73e+yXHX3/hKf//zns/auu+4a\n4wMOOCDLTZw4McbbbrttlpuXSyZqjaUnTQAABRRNAAAFFE0AAAXabsuBt99+O8bpq8ohhLDeeuvF\nuLpOYqGFForxwIEDY/zNb36z5r0uuuiimrn3338/azvyoessuuiiWTt9vbW6dmbo0KHd0qe+orql\nw9Zbb13zs2+88UaMq+MwYcKE1naMHqm63UqqutaT7nPwwQfH+NJLL81yI0aMiPH48eOzXLpNRHps\n2YYbbph9Ll0LfP/992e57bbbLsa9YdsXT5oAAAoomgAACrTdlgP8r976Giyz15PH84477ohx+kg+\nhBC+/e1vx/jxxx9v9a17pZ48ll0hnYqpbitwyCGHxLi3fn+0w3iuttpqWXv48OExXnrppbPckCFD\nYvzb3/625jWvu+66GFeXqrzyyisN9bOr2XIAAKAJiiYAgAKKJgCAAtY09QHtMM/OLMazfRjL9mI8\n24c1TQAATVA0AQAUUDQBABRQNAEAFFA0AQAUUDQBABRQNAEAFFA0AQAUUDQBABTo8h3BAQDagSdN\nAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAA\nBRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUU\nTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0A\nAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAF\nFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRN\nAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAA\nBRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUU\nTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0A\nAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAF\nFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRN\nAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAA\nBRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUU\nTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRRNAAAFFE0AAAUUTQAABRbo6ht0dHR0\ndvU9qK+zs7OjFdcxlj2D8WwfxrK9GM/2UWssPWkCACigaAIAKKBoAgAooGgCACigaAIAKKBoAgAo\noGgCACigaAIAKKBoAgAooGgCACigaAIAKKBoAgAo0OUH9gLA3DjhhBOy9sCBA2O83377Zbn555+/\nO7oEIQRPmgAAiiiaAAAKdHR2dnbtDTo6uvYGzFFnZ2dHK67Tk8Zy0KBBMV5ggXyWeebMmTGePHly\nN/Wo+7TjePZVxnKWNdZYI8bXXHNNllthhRVqft2oUaNiPHLkyCz3zjvvtKh3ZYxn+6g1lp40AQAU\nUDQBABRQNAEAFLCmqQfo379/jEeMGJHlBgwYEONzzjknyz3yyCNF12+HefZdd901a1900UUx7tev\nX5Z79913Y3zDDTc0dL8HHngga48fPz7G//rXvxq6Zqu0w3h2tbvuuitrb7LJJjG+/fbbs9yWW27Z\nHV2aLWM5y6233hrjzTbbrPjr5ptv1v/7V8dywoQJzXdsLhjP2VtyySVj/LWvfS3LfeELX4jxuHHj\nstx1113XtR2rw5omAIAmKJoAAArYEbybfOYzn4nxySefnOXWXXfdGH/sYx+reY1VVlkla2+11VYt\n6l3Pt/vuu2ft6pRcauGFF47xjjvu2ND9ql+Xbmtw0kknNXRNutaQIUNivP7662e5Dz/8MMbpVF0I\n+ZTObbfd1kW9o+rYY4/N2tUxa8Spp56atTfccMOmr0mZdJo0/XsXQgi/+tWvYrzeeuvVvMYyyyyT\ntefl9FwtnjQBABRQNAEAFFA0AQAUsKaphRZffPEYX3755VkuXX/U0dHYW6nPPPNMYx1rA/vuu2/W\nTteFLbbYYg1dc7nllsvam2++eUPXofukx2kcd9xxWW6vvfaKcb2T76vH7qSvQ9O19ttvvxj/6Ec/\nynLpurNGLbXUUk1fg9rSdUshhLD99tvHeJ999onx0KFDs89NmTIlxmeccUaW22OPPVrZxS7nSRMA\nQAFFEwBAAdNzcyl97L/xxhtnuYMOOijG6evPzfjtb38b4yOPPLIl1+yNpk+fnrUPOOCApq95wgkn\nZG3Tcz1DdQpg2LBhMW7FtCzdp/oK+d577x3j6jg3Kr1Oo0sfqC3dBqe6TcR3vvOdGL/++usxTv8W\nhhDCeeedF+PBgwdnuVb8Lu9OnjQBABRQNAEAFFA0AQAU6FNrmtLjNdI51hDy1/n/8Ic/xPjxxx/P\nPpfOyadbw8+NF198MWvfdNNNMX7iiSey3AUXXBDj//znPw3dj1k+97nPxbg6P5+67777svZpp53W\nZX0ihNVXXz3G1WNqqq8v/9cbb7yRtU888cQYV49DmTRpUrNdpNASSywR4+qp9ek60OoWA63YcqCz\ns7Ppa/RFH/3oR2Nc3d5lxIgRMU7HNoT8b1m69vCPf/xjzXulW/OEkB+JNWHChMIezzueNAEAFFA0\nAQAU6FPTc+mUXDrNVlXdqbYR1Sm4M888M8Znn312lnv33Xebvh+zV32cnO4iXX3l+Z133olxOtVT\nzdG8ww8/PGt/73vfi/Gyyy5b8+suvPDCGI8cOTLLTZ48Ocb1to+oTuvdfffddfvK3Pnud78b4y23\n3HIe9oRaqrvgpz8Dq666apZ79dVXY5yObQghjB07NsbVn6tG3HvvvU1fo6t50gQAUEDRBABQQNEE\nAFCgrdc07brrrlm73jqmRvzzn//M2ulapZ/97GdZ7oMPPmjpvZmlenTCuuuuG+Pf/e53WW7llVeu\neZ1f/vKXMa73yixlqmuTfvOb38R4k002yXLp8UTV9WPp1hDpGNVbC/iVr3ylZq66ncTUqVNrfpbZ\nS49HSbfxCCE/WoN5p/p7cbfddotxdd1u+nvxT3/6U5Y7+OCDY/zss8823a/Pf/7zNXMzZsxo+vpd\nzZMmAIACiiYAgAJtPT13/fXXZ+0nn3wyxtXXKtPdts8999wYr7322tnn0p2hq4/533rrrcY7S8MW\nXHDBrD1x4sSan00fWT/yyCNZrroVBHMv/Xm5/fbbs1y663DVlClTYnzEEUdkucsuu6zo3h//+Mdj\nvP/++9f83NVXX110PWpLxyTd5Zue4+c//3nWTqfZpk+fnuUOPPDAGI8ZM6blfUlP46huB5JOs0+b\nNq3l9241T5oAAAoomgAACiiaAAAKdHT1qdAdHR3z7NjpRRZZJGvff//9MV5jjTWyXHoq+nbbbRfj\ndlin1NnZ2THnT83ZvBzLqkGDBsU4nY8PIYQf/OAHNb/u0UcfjfFmm22W5VpxDEB36EnjueKKK2bt\nxx57LMb9+/dv6JrV9Rb//ve/i74uXTNV7yiW9HsghHxrknTdY3foSWNZlW4rUF1Xlv7sfPjhhw1d\nv3qMUfoq+oABA7LcuHHjYvyRj3yk5nWqr8SvssoqDfWtUT1pPKt/29N2db1Tup7z6aefbvbW/2Ot\ntdaK8UMPPZTlbrnllhgPGTKk5fduVK2x9KQJAKCAogkAoEBbbzlQ3Vk4nYKrTs+lp3Gnj56ru6PS\nM1x11VUxrm4LUc8ZZ5wR494yHdeTVadmWrHzfXVqptpu1pprrpm106mJrbfeuqX36s3SKfDqdGc6\n7o1Oz914441Z++GHH45xugVMCCG8/PLLMe7Xr1/Na3b1cpPeZPvtt8/a6VY6hx56aJZLtyN48MEH\ns1y6dc+tt96a5V566aUYNzqtd9NNNzX0dfOKJ00AAAUUTQAABdp6eq5q1KhRMd5iiy2yXLq6P32M\nOWLEiOxz6QGwM2fObHUXSaTTA9dee22W+/SnP93QNVdaaaVmujTXdt999xgff/zxWW6JJZaIcfqm\nUm/ywgsvZO0NNtggxoccckiWqzetkv73b7PNNlnu4osvjnF6EO9SSy01V32t5YknnmjJdXq76kGq\n6VtOgwcPznK///3vYzx06NCG7nfeeedl7XRKrtqXxRdfvKF79GXVEzHuuOOOGFcPzN55551jnP4M\nhxDCCSecMNs4hBDee++9GD/zzDM1+/LKK6/UzH3zm9+M8aKLLlrz6/7yl7/UvMZyyy2XtdOf6cmT\nJ9f8ukZ40gQAUEDRBABQQNEEAFCgrXcEr6e6k/FTTz0V4wUXXDDGr7/+eva59PX2559/vot611o9\naZfaelZeeeWs/ec//znGrVqL9OKLL8b4uOOOy3LpOo160p2nQ8h3JE93lw4hhE9+8pM1r3PaaafF\nePjw4UX3DqH3jOfcSHd1nn/++bPc+++/H+MFFpi1DDPdPiKEEA466KDZfk0I+Tqpu+66K8ul2yQ0\n+vp8o3rSWO6zzz5ZO90SoLor+ze+8Y0Yjxkzpvge6fd5dfy22mqrGKdrR0Oov6Yp/d5J1+aEkG9N\n0h160ng2Kv0ZCyFfP7rttttmuXSrnnpbg6RbVgwcOLDZLs7RjBkzYlw9MeKSSy4puoYdwQEAmqBo\nAgAo0Cun53784x/H+N57781yN9xwQ0PX/OxnPxvjK664IsbVaaEDDjggxqNHj27oXt2tJz8yTg/U\nrO6+Xp2uq6U6TZq+Kp2+oh5CCB0ds/4pGv3eT68xN9d58803s3b6qna6W/2c9OTx7E5nnXVW1k63\nOKh+T5R+L3W33jqWEyZMiPHGG29c/HXf+ta3YpwewhtCvtt09TDteu6+++4YV6fHSw97bpXeOp5d\nLZ3Wu+6667LcySefHON6U73VrS0WXnjhmrnVVlstxtWdyqvbLdRieg4AoAmKJgCAAoomAIACveIY\nlbFjx2btvffeO8bV9STpicnpMRUhhHD00UfHuLqG5K9//WuM02NUTjnllOxzG264YYx7y5qmnqS6\ntiRdx1Rv3Un11PP0VeJhw4ZluXTLiOq6iZ122qm8szXUW8OUvuoaQn50SvVV94kTJzbdl75so402\nqpm77777urEnfU+65mhutmnYdNNNZ3uNEP73aKtS48ePj3F3r2Fi9vr375+1Dz300JqfTbcAqHfk\nyc9//vOauVNPPTVrp0csVdegNsuTJgCAAoomAIACvWJ67o033qiZqz56+9KXvlTzs+krrZMmTcpy\n6S7E9XafrneSM3N2yy23ZO3qzuypBx98MMZHHnlklrv55ptrft3MmTNjnJ6gHUK+y/Eee+xRv7OF\n0ldo77zzziz3wAMPtOQe/J90Knbdddet+bmRI0d2R3f6jKWXXjprp1NyczM9t++++8Y43cl7bq6T\nnnwfQgjnn39+8f3pHoMGDcraQ4YMifEjjzyS5Z588smW3//VV19t+TX/y5MmAIACiiYAgAKKJgCA\nAr1iTVN1/dHf//73GA8ePDjLVU9orqXeeojUiBEjsnZ6Mj1z75e//GXW3mCDDWI8derULHfsscfG\nuN66tnqqWwBccMEFs43pudItJNJjjKrrGR9//PEYV49OoDnVrVe6W/oq+s477zzvOkKRdO1aVXWr\nlXQNam+MjcAFAAACSElEQVTgSRMAQAFFEwBAgY5GT3ovvkEXn9b89a9/PWunr7FuueWWWS498b66\nW/iUKVNinO4+vf7662efe+uttxrv7Dzi5O320tfGc4cddojx73//+5qfS6fOq1tU9FS9ZSzTHZZD\nCGHatGkxnpstB1L1thyo7gyd/u7+29/+1tD9ukNvGc+ukC6VeeKJJ7Jc+ndz7bXXznL1dgGfl2qN\npSdNAAAFFE0AAAUUTQAABXrFlgP1pCdcV40dOzZrL7PMMjFeddVVs9wdd9wR44033jjGjc7XA41J\njzQKIYSjjjpqtp+77bbbsvbo0aO7rE99XfVYivToknqvl8+NUaNGxfiKK67Icj15HRP/Z7nllotx\n9Wf4ueeei3FPXcNUypMmAIACiiYAgAK9fssB5qwvvwbbjtp9PLfZZpusfcMNN8z2c2uttVbWTncE\n7y3afSz7mr48nkcffXSMR44cmeWGDRsW4zFjxnRbn5phywEAgCYomgAACiiaAAAK9PotB4D2Ut0O\nJJWulfAaOvQc55xzTowfeuihLHfjjTd2d3e6jCdNAAAFFE0AAAVsOdAH9OXXYNuR8WwfxrK9GM/2\nYcsBAIAmKJoAAAoomgAACiiaAAAKKJoAAAoomgAACnT5lgMAAO3AkyYAgAKKJgCAAoomAIACiiYA\ngAKKJgCAAoomAIACiiYAgAKKJgCAAoomAIACiiYAgAKKJgCAAoomAIACiiYAgAKKJgCAAoomAIAC\niiYAgAKKJgCAAoomAIACiiYAgAKKJgCAAv8PXtd5UdbCQoAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d492400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's try to visualize some of these. The format of the images are 28x28.\n",
    "SHOW_IMAGE = 10\n",
    "\n",
    "for i in range(SHOW_IMAGE):\n",
    "    plt.subplot(SHOW_IMAGE/5, SHOW_IMAGE/2, i+1)\n",
    "    implot = plt.imshow(X_train[i].reshape((28,28)))\n",
    "    plt.axis('off')\n",
    "\n",
    "print(\"Labels, in order: \", np.where(y_train[:i+1] == 1)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's build a neural network for this!\n",
    "# We have the architecture CONV -> RELU -> FC -> RELU -> FC -> SOFTMAX\n",
    "\n",
    "def init_weight(shape, std = 0.01):\n",
    "    return tf.Variable(tf.random_normal(shape, std))\n",
    "\n",
    "def init_model(params):\n",
    "    X, W0, W1, W2, W3, W4, W5, conv_dropout, fc_dropout = params\n",
    "    \n",
    "    ##### STARTING CONV #####\n",
    "    # First we want to CONV the X to conv_1\n",
    "    conv_0 = tf.nn.conv2d(X, W0, [1,1,1,1], padding='SAME')\n",
    "    batch_0 = tf.nn.batch_normalization(drop_0, mean[0], variance[0], offset[0], scale, variance_epsilon, name=None)\n",
    "    relu_0 = tf.nn.relu(conv_0)\n",
    "    drop_0 = tf.nn.dropout(relu_0, conv_dropout)\n",
    "    # Then, we want to CONV the conv_1 to conv_2\n",
    "    conv_1 = tf.nn.conv2d(drop_0, W1, [1,1,1,1], padding='SAME')\n",
    "    relu_1 = tf.nn.relu(conv_1)\n",
    "    drop_1 = tf.nn.dropout(relu_1, conv_dropout)\n",
    "    \n",
    "    # Then, we want to POOL the conv_2\n",
    "    pool_1 = tf.nn.max_pool(relu_1, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # Then, we want to CONV the pool_2 to conv_3\n",
    "    conv_2 = tf.nn.conv2d(pool_1, W2, [1,1,1,1], padding='SAME')\n",
    "    relu_2 = tf.nn.relu(conv_2)\n",
    "    drop_2 = tf.nn.dropout(relu_2, conv_dropout)\n",
    "\n",
    "    \n",
    "    # Then, we want to POOL the conv_3\n",
    "    pool_2 = tf.nn.max_pool(relu_2, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # Then, we want to CONV the pool_3\n",
    "    conv_3 = tf.nn.conv2d(pool_2, W3, [1,1,1,1], padding='SAME')\n",
    "    relu_3 = tf.nn.relu(conv_3)\n",
    "    drop_3 = tf.nn.dropout(relu_3, conv_dropout)\n",
    "\n",
    "    \n",
    "    ##### STARTING FC #####\n",
    "    # Then we need to unroll this result and start FC\n",
    "    fc_3 = tf.reshape(conv_3, [-1, 7*7*64])\n",
    "    fc_4 = tf.matmul(fc_3, W4)\n",
    "    relu_4 = tf.nn.relu(fc_4)\n",
    "    drop_4 = tf.nn.dropout(relu_4, fc_dropout)\n",
    "    \n",
    "    # Then we need to fc again to get the result\n",
    "    fc_5 = tf.matmul(relu_4, W5)\n",
    "    \n",
    "    answer = fc_5\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Variable is a starting point. tf.random_normal initializes it for us with a stddev\n",
    "input_shape = X_train.shape\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "############################# CONVOLUTIONAL LAYER INITIALIZATION #############################\n",
    "# Each layer is in the form of [NxHxWxC]\n",
    "# We start off with a layer of [Nx28x28x1]\n",
    "# We change it to a layer of [Nx28x28x64] from CONV a filter of [3x3], padding 1\n",
    "# Therefore, we need the weight [filter_height = 3, filter_width = 3, in_channels = 1, out_channels = 64]\n",
    "W0 = init_weight([3,3,1,64])\n",
    "\n",
    "# Then, we change it to a layer of [Nx28x28x64] from CONV a filter of [3x3], padding 1\n",
    "# Therefore, we need the weight [filter_height = 3, filter_width = 3, in_channels = 64, out_channels = 64\n",
    "W1 = init_weight([3,3,64,64])\n",
    "\n",
    "# Then, we change it to a layer of [Nx14x14x64] from POOLING with filter of [2x2] with stride 2\n",
    "# No weights necessary.\n",
    "\n",
    "# Then, we change it to a layer of [Nx14x14x64] from CONV with a filter of [3x3], padding 1\n",
    "# Therefore, we need the weight [filter_height = 3, filter_width = 3, in_channels = 64, out_channels = 128]\n",
    "W2 = init_weight([3,3,64,128])\n",
    "\n",
    "# Then, we get the layer of [Nx7x7x128] from POOLING with filter of [2x2] with stride 2\n",
    "# No weights necessary.\n",
    "\n",
    "# Then, we get the layer of [Nx7x7x64] from CONV with a filter of [3x3], padding 1\n",
    "# Therefore, we need the weight [filter_height = 3, filter_width = 3, in_channels = 128, out_channels = 64]\n",
    "W3 = init_weight([3,3,128,64])\n",
    "################################################################################################\n",
    "\n",
    "############################# FULLY CONNECTED LAYERS INITIALIZATION #############################\n",
    "# We need to unroll the parameters of the CONV layer, and we get an input of [Nx(7x7x64)]\n",
    "W4 = init_weight([7*7*64, 300])\n",
    "\n",
    "# Then, we do one more FC before we feed into softmax:\n",
    "W5 = init_weight([300, 10])\n",
    "################################################################################################\n",
    "\n",
    "#################################### EXTRA PARAMETERS ####################################\n",
    "conv_dropout = tf.placeholder(tf.float32)\n",
    "fc_dropout = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparams:\n",
    "learning_rate = 1e-4\n",
    "reg_rate = 1e-4\n",
    "\n",
    "hypothesis = init_model((X, W0, W1, W2, W3, W4, W5, conv_dropout, fc_dropout))\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(hypothesis, y))\n",
    "\n",
    "# Regularization \n",
    "cross_entropy += reg_rate * (tf.nn.l2_loss(W0)+tf.nn.l2_loss(W1)+tf.nn.l2_loss(W2)\n",
    "                             +tf.nn.l2_loss(W3)+tf.nn.l2_loss(W4)+tf.nn.l2_loss(W5))\n",
    "\n",
    "# Using Adam to optimize\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "predict_op = tf.argmax(hypothesis, 1)\n",
    "\n",
    "# Let's log it to see our progress!\n",
    "loss_summary = tf.scalar_summary('loss', cross_entropy)\n",
    "\n",
    "# Reshape the matrices into the correct conv dimensions:\n",
    "X_train = X_train.reshape(-1,28,28,1)\n",
    "X_val = X_val.reshape(-1,28,28,1)\n",
    "teX = teX.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :  1.24869e+07\n",
      "0 0.09765625\n",
      "Loss :  1.07745e+07\n",
      "1 0.13671875\n",
      "Loss :  8.54806e+06\n",
      "2 0.11328125\n",
      "Loss :  6.9705e+06\n",
      "3 0.14453125\n",
      "Loss :  5.64172e+06\n",
      "4 0.12890625\n",
      "Loss :  5.25852e+06\n",
      "5 0.1875\n",
      "Loss :  4.63622e+06\n",
      "6 0.203125\n",
      "Loss :  4.17056e+06\n",
      "7 0.1796875\n",
      "Loss :  3.45193e+06\n",
      "8 0.26171875\n",
      "Loss :  3.39095e+06\n",
      "9 0.2734375\n",
      "Loss :  2.8567e+06\n",
      "10 0.2734375\n",
      "Loss :  2.87599e+06\n",
      "11 0.3828125\n",
      "Loss :  2.91606e+06\n",
      "12 0.3984375\n",
      "Loss :  2.32616e+06\n",
      "13 0.39453125\n",
      "Loss :  2.19092e+06\n",
      "14 0.43359375\n",
      "Loss :  2.223e+06\n",
      "15 0.4453125\n",
      "Loss :  1.94056e+06\n",
      "16 0.47265625\n",
      "Loss :  2.4266e+06\n",
      "17 0.5078125\n",
      "Loss :  2.23955e+06\n",
      "18 0.4609375\n",
      "Loss :  1.79095e+06\n",
      "19 0.546875\n",
      "Loss :  1.33303e+06\n",
      "20 0.55859375\n",
      "Loss :  1.40051e+06\n",
      "21 0.4765625\n",
      "Loss :  1.29897e+06\n",
      "22 0.62890625\n",
      "Loss :  1.40351e+06\n",
      "23 0.5390625\n",
      "Loss :  1.82460e+06\n",
      "24 0.5625\n",
      "Loss :  1.47272e+06\n",
      "25 0.58203125\n",
      "Loss :  1.58832e+06\n",
      "26 0.6171875\n",
      "Loss :  1.05445e+06\n",
      "27 0.65234375\n",
      "Loss :  1.6348e+06\n",
      "28 0.68359375\n",
      "Loss :  1.662e+06\n",
      "29 0.6328125\n",
      "Loss :  1.40786e+06\n",
      "30 0.5625\n",
      "Loss :  878385.0\n",
      "31 0.625\n",
      "Loss :  1.49385e+06\n",
      "32 0.6640625\n",
      "Loss :  711702.0\n",
      "33 0.65234375\n",
      "Loss :  1.22882e+06\n",
      "34 0.68359375\n",
      "Loss :  833605.0\n",
      "35 0.66015625\n",
      "Loss :  971511.0\n",
      "36 0.67578125\n",
      "Loss :  999288.0\n",
      "37 0.74609375\n",
      "Loss :  1.13713e+06\n",
      "38 0.74609375\n",
      "Loss :  1.29319e+06\n",
      "39 0.66015625\n",
      "Loss :  1.02703e+06\n",
      "40 0.6796875\n",
      "Loss :  1.01399e+06\n",
      "41 0.67578125\n",
      "Loss :  1.31792e+06\n",
      "42 0.75390625\n",
      "Loss :  1.06089e+06\n",
      "43 0.7265625\n",
      "Loss :  850281.0\n",
      "44 0.70703125\n",
      "Loss :  888257.0\n",
      "45 0.6796875\n",
      "Loss :  945017.0\n",
      "46 0.6953125\n",
      "Loss :  864842.0\n",
      "47 0.7734375\n",
      "Loss :  911149.0\n",
      "48 0.75390625\n",
      "Loss :  905144.0\n",
      "49 0.75\n",
      "Loss :  752431.0\n",
      "50 0.7578125\n",
      "Loss :  829439.0\n",
      "51 0.7578125\n",
      "Loss :  794417.0\n",
      "52 0.7578125\n",
      "Loss :  826612.0\n",
      "53 0.7734375\n",
      "Loss :  1.02995e+06\n",
      "54 0.76171875\n",
      "Loss :  748245.0\n",
      "55 0.76171875\n",
      "Loss :  875897.0\n",
      "56 0.7890625\n",
      "Loss :  878267.0\n",
      "57 0.765625\n",
      "Loss :  657656.0\n",
      "58 0.7421875\n",
      "Loss :  698120.0\n",
      "59 0.7734375\n",
      "Loss :  587761.0\n",
      "60 0.75390625\n",
      "Loss :  899124.0\n",
      "61 0.71875\n",
      "Loss :  579549.0\n",
      "62 0.83984375\n",
      "Loss :  629385.0\n",
      "63 0.76953125\n",
      "Loss :  624296.0\n",
      "64 0.7890625\n",
      "Loss :  805277.0\n",
      "65 0.78515625\n",
      "Loss :  734185.0\n",
      "66 0.80859375\n",
      "Loss :  730995.0\n",
      "67 0.796875\n",
      "Loss :  635407.0\n",
      "68 0.7578125\n",
      "Loss :  545766.0\n",
      "69 0.83984375\n",
      "Loss :  600210.0\n",
      "70 0.8046875\n",
      "Loss :  699146.0\n",
      "71 0.8046875\n",
      "Loss :  885888.0\n",
      "72 0.8203125\n",
      "Loss :  500900.0\n",
      "73 0.796875\n",
      "Loss :  640524.0\n",
      "74 0.8046875\n",
      "Loss :  592356.0\n",
      "75 0.828125\n",
      "Loss :  443894.0\n",
      "76 0.8046875\n",
      "Loss :  449812.0\n",
      "77 0.79296875\n",
      "Loss :  583840.0\n",
      "78 0.828125\n",
      "Loss :  540585.0\n",
      "79 0.81640625\n",
      "Loss :  708843.0\n",
      "80 0.78125\n",
      "Loss :  563251.0\n",
      "81 0.85546875\n",
      "Loss :  634315.0\n",
      "82 0.8046875\n",
      "Loss :  564644.0\n",
      "83 0.82421875\n",
      "Loss :  450027.0\n",
      "84 0.80859375\n",
      "Loss :  452670.0\n",
      "85 0.8203125\n",
      "Loss :  594549.0\n",
      "86 0.8515625\n",
      "Loss :  446056.0\n",
      "87 0.83984375\n",
      "Loss :  594830.0\n",
      "88 0.8125\n",
      "Loss :  515477.0\n",
      "89 0.83203125\n",
      "Loss :  329427.0\n",
      "90 0.7890625\n",
      "Loss :  547492.0\n",
      "91 0.83984375\n",
      "Loss :  759949.0\n",
      "92 0.8515625\n",
      "Loss :  650587.0\n",
      "93 0.828125\n",
      "Loss :  470526.0\n",
      "94 0.8359375\n",
      "Loss :  791207.0\n",
      "95 0.86328125\n",
      "Loss :  558851.0\n",
      "96 0.82421875\n",
      "Loss :  615891.0\n",
      "97 0.828125\n",
      "Loss :  350250.0\n",
      "98 0.859375\n",
      "Loss :  584058.0\n",
      "99 0.8515625\n",
      "Model saved in file: model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    #merged = tf.merge_all_summaries([loss_summary])\n",
    "    writer = tf.train.SummaryWriter('logs', sess.graph_def)\n",
    "    # you need to initialize all variables\n",
    "    tf.initialize_all_variables().run()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    for i in range(100):\n",
    "        NUM_BATCHES = 10\n",
    "        for j in range(NUM_BATCHES):\n",
    "            batch_mask = np.random.choice(44000, 128)\n",
    "            summary_str, _, cur_loss = sess.run([loss_summary, train_op, cross_entropy], \n",
    "                                                feed_dict={X: X_train[batch_mask], \n",
    "                                                           y: y_train[batch_mask],\n",
    "                                                           conv_dropout: 0.8, \n",
    "                                                           fc_dropout: 0.5})\n",
    "\n",
    "        test_indices = np.arange(len(X_val)) # Get a validation batch\n",
    "        np.random.shuffle(test_indices)\n",
    "        test_indices = test_indices[0:256]\n",
    "\n",
    "        writer.add_summary(summary_str, i)\n",
    "        print(\"Loss : \" , cur_loss)\n",
    "        print(i, np.mean(np.argmax(y_val[test_indices], axis=1) ==\n",
    "                         sess.run(predict_op, feed_dict={X: X_val[test_indices],\n",
    "                                                         y: y_val[test_indices],\n",
    "                                                         conv_dropout: 1.0,\n",
    "                                                         fc_dropout: 1.0})))\n",
    "        \n",
    "    save_path = saver.save(sess, \"model.ckpt\") # checkpoint file\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers :  [7 2 1 0 4 1 7 9 5 9]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAFzCAYAAAAjYj0YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1112ce860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"model.ckpt\")\n",
    "    answers = sess.run(predict_op, feed_dict={X: teX[:SHOW_IMAGE],\n",
    "                                     y: teY[:SHOW_IMAGE],\n",
    "                                     conv_dropout: 1.0,\n",
    "                                     fc_dropout: 1.0})\n",
    "    for i in range(SHOW_IMAGE):\n",
    "        plt.subplot(SHOW_IMAGE/5, SHOW_IMAGE/2, i+1)\n",
    "        implot = plt.imshow(teX[i].reshape((28,28)))\n",
    "        plt.axis('off')\n",
    "    print(\"Answers : \", answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
